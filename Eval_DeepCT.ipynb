{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sl9Z9bnB1lCp"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/NThakur20/DeepCT.git\n",
        "!pip install beir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYn1V6nyQkKR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KJYJvXt12CZ"
      },
      "outputs": [],
      "source": [
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "# BEFORE RUNNING THIS OPEN DEEPCT/DEEPCT/MODDELING.PY AND CHANGE LINE 339 TO assignment_map[name] = name_to_variable[name]\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "\n",
        "from DeepCT.deepct import run_deepct                            # git clone https://github.com/NThakur20/DeepCT.git\n",
        "\n",
        "from beir import util, LoggingHandler\n",
        "from beir.datasets.data_loader import GenericDataLoader\n",
        "from beir.retrieval.evaluation import EvaluateRetrieval\n",
        "from beir.generation.models import QGenModel\n",
        "from tqdm.autonotebook import trange\n",
        "\n",
        "import pathlib, os, json\n",
        "import logging\n",
        "import requests\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-5x92KWm4Suc"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
        "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
        "                    level=logging.INFO,\n",
        "                    handlers=[LoggingHandler()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_N8GhNz2A7j"
      },
      "outputs": [],
      "source": [
        "dataset = \"nfcorpus\"\n",
        "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
        "out_dir = \"datasets\"\n",
        "data_path = util.download_and_unzip(url, out_dir)\n",
        "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s--UYRc52f8h"
      },
      "outputs": [],
      "source": [
        "base_model_url = \"https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\"\n",
        "out_dir = \"models\"\n",
        "bert_base_dir = util.download_and_unzip(base_model_url, out_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "izUzgNsV2ulQ"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = \"DeepCT_Trained\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tauWVvlanJHQ"
      },
      "outputs": [],
      "source": [
        "run_deepct.flags.DEFINE_string('f', '', 'kernel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvONIKk-22jm"
      },
      "outputs": [],
      "source": [
        "# the checkpoint number of the init_checkpoint has to be set\n",
        "\n",
        "if not os.path.isfile(os.path.join(checkpoint_dir, \"deepct.jsonl\")):\n",
        "    ################################\n",
        "    #### Command-Line Arugments ####\n",
        "    ################################\n",
        "    run_deepct.FLAGS.task_name = \"beir\"                                                     # Defined a seperate BEIR task in DeepCT. Check out run_deepct.\n",
        "    run_deepct.FLAGS.do_train = False                                                       # We only want to use the code for inference.\n",
        "    run_deepct.FLAGS.do_eval = False                                                        # No evaluation.\n",
        "    run_deepct.FLAGS.do_predict = True                                                      # True, as we would use DeepCT model for only prediction.\n",
        "    run_deepct.FLAGS.data_dir = data_path + \"/corpus.jsonl\"                    # Provide original path to corpus data, follow beir format.\n",
        "    run_deepct.FLAGS.vocab_file = bert_base_dir + \"/vocab.txt\"                 # Provide bert-base-uncased model vocabulary.\n",
        "    run_deepct.FLAGS.bert_config_file = bert_base_dir + \"/bert_config.json\"     # Provide bert-base-uncased config.json file.\n",
        "    run_deepct.FLAGS.init_checkpoint = checkpoint_dir + \"/model.ckpt-{ckpt-number}\"     # Provide DeepCT MSMARCO model (bert-base-uncased) checkpoint file.\n",
        "    run_deepct.FLAGS.max_seq_length = 350                                                   # Provide Max Sequence Length used for consideration. (Max: 512)\n",
        "    run_deepct.FLAGS.train_batch_size = 128                                                 # Inference batch size, Larger more Memory but faster!\n",
        "    run_deepct.FLAGS.output_dir = checkpoint_dir                                                 # Output directory, this will contain two files: deepct.jsonl (output-file) and predict.tf_record\n",
        "    run_deepct.FLAGS.output_file = \"deepct.jsonl\"                                           # Output file for storing final DeepCT produced corpus.\n",
        "    run_deepct.FLAGS.m = 100                                                                # Scaling parameter for DeepCT weights: scaling parameter > 0, recommend 100\n",
        "    run_deepct.FLAGS.smoothing = \"sqrt\"                                                     # Use sqrt to smooth weights. DeepCT Paper uses None.\n",
        "    run_deepct.FLAGS.keep_all_terms = True                                                  # Do not allow DeepCT to delete terms.\n",
        "\n",
        "    # Runs DeepCT model on the corpus.jsonl\n",
        "    run_deepct.main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook covers the step for the DeepCT evaluation from HuggingFace until the part where Docker is used (https://github.com/beir-cellar/beir/blob/main/examples/retrieval/evaluation/sparse/evaluate_deepct.py). The rest of the evaluatoin cannot be done in a notebook but have to be done on a machine where Docker can be installed. The deepct.jsonl created with this notebook can be used for the evaluation with Docker.\n",
        "\n",
        "If Docker runs out of Java heap space add -e JAVA_TOOL_OPTIONS=\"-Xmx12800m\" to the docker run command."
      ],
      "metadata": {
        "id": "3dDdmbRHJaBj"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}